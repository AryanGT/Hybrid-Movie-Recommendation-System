{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4508,"sourceType":"datasetVersion","datasetId":138}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aryantete/hybrid-movie-recommendation-system?scriptVersionId=231400667\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Hybrid Movie Recommender","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import TruncatedSVD\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Set a Seaborn theme for improved visuals\nsns.set_theme(style=\"whitegrid\", palette=\"muted\")\n\n# Suppress extra TensorFlow logs\ntf.get_logger().setLevel('ERROR')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\n# ============================\n# Helper Function for File Paths\n# ============================\ndef get_file_path(filename, folder):\n    \"\"\"\n    Returns the full file path for Kaggle input data.\n    \"\"\"\n    kaggle_dir = f\"/kaggle/input/{folder}\"\n    full_path = os.path.join(kaggle_dir, filename)\n    return full_path if os.path.exists(full_path) else filename","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:06:05.70526Z","iopub.execute_input":"2025-04-02T19:06:05.705691Z","iopub.status.idle":"2025-04-02T19:06:25.147846Z","shell.execute_reply.started":"2025-04-02T19:06:05.705659Z","shell.execute_reply":"2025-04-02T19:06:25.146599Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Loading Functions","metadata":{}},{"cell_type":"code","source":"# ============================\n# Data Loading Functions\n# ============================\ndef load_tmdb_data():\n    \"\"\"\n    Loads TMDB movies and credits from the 'tmdb-movie-metadata' dataset.\n    \"\"\"\n    print(\"Loading TMDB movies and credits...\")\n    tmdb_movies = pd.read_csv(get_file_path(\"tmdb_5000_movies.csv\", \"tmdb-movie-metadata\"))\n    tmdb_credits = pd.read_csv(get_file_path(\"tmdb_5000_credits.csv\", \"tmdb-movie-metadata\"))\n    print(\"TMDB movies shape:\", tmdb_movies.shape)\n    print(\"TMDB credits shape:\", tmdb_credits.shape)\n    \n    # Merge movies and credits data\n    tmdb_data = tmdb_movies.merge(tmdb_credits, left_on='id', right_on='movie_id')\n    \n    # Handle title column discrepancies\n    if 'title' not in tmdb_data.columns and 'original_title' in tmdb_data.columns:\n        tmdb_data.rename(columns={'original_title': 'title'}, inplace=True)\n    for col in ['title_x', 'title_y']:\n        if col in tmdb_data.columns:\n            tmdb_data.drop(columns=[col], inplace=True)\n    \n    # Remove vote_count as requested\n    if 'vote_count' in tmdb_data.columns:\n        tmdb_data = tmdb_data.drop(columns=['vote_count'])\n    \n    # Create a common key for title\n    tmdb_data['title_tmdb'] = tmdb_data['title']\n    \n    print(\"Processed TMDB data shape:\", tmdb_data.shape)\n    return tmdb_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:06:25.14919Z","iopub.execute_input":"2025-04-02T19:06:25.149867Z","iopub.status.idle":"2025-04-02T19:06:25.157217Z","shell.execute_reply.started":"2025-04-02T19:06:25.149819Z","shell.execute_reply":"2025-04-02T19:06:25.15589Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"# ============================\n# Feature Engineering\n# ============================\ndef create_synthetic_rating_matrix(movies, n_synthetic_users=100):\n    \"\"\"\n    Creates a synthetic user-item rating matrix from TMDB data.\n    This allows us to use SVD even without real user ratings.\n    \"\"\"\n    # Get unique movie IDs\n    movie_ids = movies['id'].unique()\n    \n    # Create empty rating matrix\n    np.random.seed(42)  # For reproducibility\n    synthetic_ratings = pd.DataFrame(index=range(1, n_synthetic_users + 1), columns=movie_ids)\n    \n    # Generate synthetic ratings based on movie features\n    for movie_id in movie_ids:\n        movie_data = movies[movies['id'] == movie_id]\n        if movie_data.empty:\n            continue\n            \n        # Get movie rating\n        base_rating = float(movie_data['vote_average'].iloc[0])\n        \n        # Generate synthetic ratings with some noise around the base rating\n        for user_id in range(1, n_synthetic_users + 1):\n            # Add random noise between -1.5 and 1.5\n            noise = np.random.uniform(-1.5, 1.5)\n            # Ensure rating is between 1 and 10\n            synthetic_rating = np.clip(base_rating + noise, 1, 10)\n            synthetic_ratings.loc[user_id, movie_id] = synthetic_rating\n    \n    # Convert to long format for SVD\n    ratings_long = synthetic_ratings.reset_index().melt(\n        id_vars='index', \n        value_vars=movie_ids,\n        var_name='movie_id', \n        value_name='rating'\n    )\n    ratings_long = ratings_long.rename(columns={'index': 'user_id'})\n    ratings_long = ratings_long.dropna()\n    \n    return synthetic_ratings, ratings_long","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:06:25.159395Z","iopub.execute_input":"2025-04-02T19:06:25.159853Z","iopub.status.idle":"2025-04-02T19:06:25.211699Z","shell.execute_reply.started":"2025-04-02T19:06:25.159812Z","shell.execute_reply":"2025-04-02T19:06:25.210395Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Content-Based Recommendation Functions","metadata":{}},{"cell_type":"code","source":"# ============================\n# Content-Based Recommendation Functions\n# ============================\ndef preprocess_content(movies):\n    \"\"\"\n    Preprocesses movie overview text data with TF-IDF.\n    \"\"\"\n    movies['overview'] = movies['overview'].fillna('')\n    tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=0.85, min_df=2)\n    tfidf_matrix = tfidf.fit_transform(movies['overview'])\n    return tfidf_matrix, tfidf\n\ndef content_based_recommender(movies, tfidf_matrix, tfidf, movie_title, top_n=10):\n    \"\"\"\n    Recommends movies based on content similarity using TF-IDF and cosine similarity.\n    \"\"\"\n    indices = pd.Series(movies.index, index=movies['title_tmdb']).drop_duplicates()\n    if movie_title not in indices:\n        return f\"Movie '{movie_title}' not found in the dataset.\"\n    \n    idx = indices[movie_title]\n    if isinstance(idx, pd.Series):\n        idx = idx.iloc[0]\n    \n    sim_scores = cosine_similarity(tfidf_matrix[idx], tfidf_matrix).flatten()\n    sorted_indices = np.argsort(sim_scores)[::-1]\n    sorted_indices = sorted_indices[sorted_indices != idx]  # Exclude query movie\n    top_indices = sorted_indices[:top_n]\n    \n    rec_titles = movies['title_tmdb'].iloc[top_indices]\n    rec_scores = sim_scores[top_indices]\n    return rec_titles, rec_scores\n    \ndef evaluate_tfidf(movies, test_size=0.2, n_similar=5):\n    \"\"\"\n    Evaluates the TF-IDF content-based approach by predicting ratings based on similar movies.\n    For each test movie, it predicts the rating as a weighted average of the n_similar most similar training movies.\n    \n    Parameters:\n      movies (DataFrame): The movies DataFrame.\n      test_size (float): Fraction of movies to use as test set.\n      n_similar (int): Number of similar movies to consider.\n    \n    Returns:\n      mse (float): Mean squared error of predictions.\n      r2 (float): R² score of predictions.\n      y_true (list): True ratings.\n      y_pred (list): Predicted ratings.\n    \"\"\"\n    # Split data into training and testing sets and reset indices\n    train_movies, test_movies = train_test_split(movies, test_size=test_size, random_state=42)\n    train_movies = train_movies.reset_index(drop=True)\n    test_movies = test_movies.reset_index(drop=True)\n    \n    # Ensure there are no missing overviews\n    train_overviews = train_movies['overview'].fillna('')\n    test_overviews = test_movies['overview'].fillna('')\n    \n    # Fit TF-IDF on the training set and transform both sets\n    tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=0.85, min_df=2)\n    train_tfidf = tfidf.fit_transform(train_overviews)\n    test_tfidf = tfidf.transform(test_overviews)\n    \n    y_true = []\n    y_pred = []\n    \n    # For each movie in the test set, find the top similar movies from the training set\n    for i in range(test_tfidf.shape[0]):\n        test_vector = test_tfidf[i]\n        # Compute cosine similarity between the test movie and all training movies\n        cosine_sim = cosine_similarity(test_vector, train_tfidf).flatten()\n        \n        # Get the indices of the top n_similar movies\n        top_indices = cosine_sim.argsort()[::-1][:n_similar]\n        \n        # Use the cosine similarity scores as weights to predict the rating\n        weights = cosine_sim[top_indices]\n        neighbor_ratings = train_movies.iloc[top_indices]['vote_average'].values\n        \n        # Check for division by zero; if weights sum is zero, use the average rating of neighbors.\n        if np.sum(weights) == 0:\n            pred_rating = np.mean(neighbor_ratings)\n        else:\n            pred_rating = np.sum(neighbor_ratings * weights) / np.sum(weights)\n        \n        y_true.append(test_movies.iloc[i]['vote_average'])\n        y_pred.append(pred_rating)\n    \n    mse = mean_squared_error(y_true, y_pred)\n    r2 = r2_score(y_true, y_pred)\n    \n    return mse, r2, y_true, y_pred\n    \ndef knn_recommender(tfidf_matrix, movies, movie_title, n_neighbors=10):\n    \"\"\"\n    Recommends movies using K-nearest neighbors based on content similarity.\n    \"\"\"\n    nbrs = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine').fit(tfidf_matrix)\n    indices = pd.Series(movies.index, index=movies['title_tmdb']).drop_duplicates()\n    \n    if movie_title not in indices:\n        return f\"Movie '{movie_title}' not found in the dataset.\"\n    \n    idx = indices[movie_title]\n    if isinstance(idx, pd.Series):\n        idx = idx.iloc[0]\n    \n    distances, indices_arr = nbrs.kneighbors(tfidf_matrix[idx])\n    rec_indices = indices_arr.flatten()[1:]  # Exclude query movie\n    distances = distances.flatten()[1:]\n    rec_titles = movies['title_tmdb'].iloc[rec_indices]\n    rec_ratings = movies['vote_average'].iloc[rec_indices]\n    \n    return rec_titles, distances, rec_ratings\n\ndef evaluate_knn(movies, test_size=0.2, n_neighbors=5):\n    \"\"\"\n    Evaluates KNN model for rating prediction using MSE and R2 score.\n    \"\"\"\n    # Split the movies into training and test sets and reset indices\n    train_movies, test_movies = train_test_split(movies, test_size=test_size, random_state=42)\n    train_movies = train_movies.reset_index(drop=True)\n    test_movies = test_movies.reset_index(drop=True)\n    \n    # Fill missing values in 'overview'\n    train_movies['overview'] = train_movies['overview'].fillna('')\n    test_movies['overview'] = test_movies['overview'].fillna('')\n    \n    # Fit TF-IDF on training data, then transform both train and test overviews\n    tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=0.85, min_df=2)\n    train_tfidf_matrix = tfidf.fit_transform(train_movies['overview'])\n    test_tfidf_matrix = tfidf.transform(test_movies['overview'])\n    \n    # Fit the KNN model on the training TF-IDF matrix\n    nbrs = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine').fit(train_tfidf_matrix)\n    \n    # Predict ratings for test movies\n    y_true = []\n    y_pred = []\n    \n    for idx, row in test_movies.iterrows():\n        movie_vector = test_tfidf_matrix[idx]\n        distances, indices = nbrs.kneighbors(movie_vector)\n        \n        # Ensure we have neighbors\n        if len(indices[0]) == 0:\n            continue\n        \n        # Actual rating of the test movie\n        actual_rating = row['vote_average']\n        \n        # Get ratings from the training set neighbors\n        neighbor_ratings = train_movies.iloc[indices[0]]['vote_average'].values\n        weights = 1 / (distances[0] + 0.0001)  # Avoid division by zero\n        pred_rating = np.sum(neighbor_ratings * weights) / np.sum(weights)\n        \n        y_true.append(actual_rating)\n        y_pred.append(pred_rating)\n    \n    # Calculate evaluation metrics\n    mse = mean_squared_error(y_true, y_pred)\n    r2 = r2_score(y_true, y_pred)\n    \n    return mse, r2, y_true, y_pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:06:25.213419Z","iopub.execute_input":"2025-04-02T19:06:25.213738Z","iopub.status.idle":"2025-04-02T19:06:25.239549Z","shell.execute_reply.started":"2025-04-02T19:06:25.213708Z","shell.execute_reply":"2025-04-02T19:06:25.238404Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SVD Recommendation Functions","metadata":{}},{"cell_type":"code","source":"# ============================\n# SVD Recommendation Functions\n# ============================\ndef train_svd_model(ratings_matrix, n_components=50):\n    \"\"\"\n    Trains an SVD model on a user-item rating matrix.\n    \"\"\"\n    # Fill missing values with the movie's mean rating\n    ratings_filled = ratings_matrix.copy()\n    for col in ratings_filled.columns:\n        ratings_filled[col].fillna(ratings_filled[col].mean(), inplace=True)\n    \n    # Apply SVD\n    svd = TruncatedSVD(n_components=n_components, random_state=42)\n    item_features = svd.fit_transform(ratings_filled.T)\n    user_features = svd.components_\n    \n    return svd, item_features, user_features\n\ndef predict_rating_svd(svd, item_features, user_id, movie_id, movie_id_map, ratings_matrix):\n    \"\"\"\n    Predicts a rating for a user-item pair using SVD.\n    \"\"\"\n    # Get column index for movie_id\n    if movie_id not in movie_id_map:\n        # If movie not in map, return mean rating\n        return np.mean(ratings_matrix.values)\n    \n    movie_idx = movie_id_map[movie_id]\n    \n    # Get reconstruction of ratings matrix\n    reconstructed = svd.inverse_transform(item_features)\n    \n    # Get predicted rating\n    predicted_rating = reconstructed[movie_idx, user_id-1]\n    \n    return predicted_rating\n\ndef svd_recommender(movies, svd, item_features, movie_id_map, ratings_matrix, user_id=1, top_n=10):\n    \"\"\"\n    Recommends movies for a user based on SVD predictions.\n    \"\"\"\n    # Get all movie IDs\n    all_movie_ids = list(movie_id_map.keys())\n    \n    # Predict ratings for all movies\n    predictions = []\n    for movie_id in all_movie_ids:\n        pred = predict_rating_svd(svd, item_features, user_id, movie_id, movie_id_map, ratings_matrix)\n        predictions.append((movie_id, pred))\n    \n    # Sort by predicted rating\n    sorted_predictions = sorted(predictions, key=lambda x: x[1], reverse=True)[:top_n]\n    \n    # Get movie titles and scores\n    rec_titles = []\n    rec_scores = []\n    \n    for movie_id, score in sorted_predictions:\n        movie_data = movies[movies['id'] == movie_id]\n        if not movie_data.empty:\n            rec_titles.append(movie_data['title_tmdb'].iloc[0])\n            rec_scores.append(score)\n    \n    return rec_titles, rec_scores\n\ndef evaluate_svd(svd, item_features, movie_id_map, ratings_matrix, ratings_long, test_size=0.2):\n    \"\"\"\n    Evaluates SVD model for rating prediction using MSE and R2 score.\n    \"\"\"\n    # Split into train and test\n    train_data, test_data = train_test_split(ratings_long, test_size=test_size, random_state=42)\n    \n    # Predict ratings for test set\n    y_true = []\n    y_pred = []\n    \n    for _, row in test_data.iterrows():\n        user_id = row['user_id']\n        movie_id = row['movie_id']\n        actual_rating = row['rating']\n        \n        pred_rating = predict_rating_svd(svd, item_features, user_id, movie_id, movie_id_map, ratings_matrix)\n        \n        y_true.append(actual_rating)\n        y_pred.append(pred_rating)\n    \n    # Calculate metrics\n    mse = mean_squared_error(y_true, y_pred)\n    r2 = r2_score(y_true, y_pred)\n    \n    return mse, r2, y_true, y_pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:06:25.240789Z","iopub.execute_input":"2025-04-02T19:06:25.241116Z","iopub.status.idle":"2025-04-02T19:06:25.269134Z","shell.execute_reply.started":"2025-04-02T19:06:25.241081Z","shell.execute_reply":"2025-04-02T19:06:25.267827Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ANN Prediction Functions","metadata":{}},{"cell_type":"code","source":"# ============================\n# ANN Prediction Functions\n# ============================\ndef train_ann_model(movies):\n    \"\"\"\n    Trains an ANN model to predict ratings using TMDB metadata.\n    \"\"\"\n    # Select relevant features for prediction\n    features = ['budget', 'popularity', 'runtime']\n    movies_ann = movies.dropna(subset=features + ['vote_average']).copy()\n    \n    X = movies_ann[features].values\n    y = movies_ann['vote_average'].values\n    \n    # Scale features and target\n    scaler_X = StandardScaler()\n    X_scaled = scaler_X.fit_transform(X)\n    \n    scaler_y = StandardScaler()\n    y_scaled = scaler_y.fit_transform(y.reshape(-1,1)).flatten()\n    \n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n    \n    # Build the model\n    model = Sequential()\n    model.add(Input(shape=(X_train.shape[1],)))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(1, activation='linear'))\n    \n    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n    \n    # Train the model\n    early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n    model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n              callbacks=[early_stop], verbose=0)\n    \n    return model, scaler_X, scaler_y, X_test, y_test\n\ndef predict_rating_ann(model, scaler_X, scaler_y, movie_features):\n    \"\"\"\n    Predicts ratings using the trained ANN model.\n    \"\"\"\n    movie_features_scaled = scaler_X.transform(movie_features)\n    pred_scaled = model.predict(movie_features_scaled, verbose=0)[0][0]\n    pred = scaler_y.inverse_transform(np.array([[pred_scaled]]))[0][0]\n    return pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:06:25.270353Z","iopub.execute_input":"2025-04-02T19:06:25.270704Z","iopub.status.idle":"2025-04-02T19:06:25.302605Z","shell.execute_reply.started":"2025-04-02T19:06:25.270672Z","shell.execute_reply":"2025-04-02T19:06:25.301443Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Hybrid Recommendations","metadata":{}},{"cell_type":"code","source":"# ============================\n# Hybrid Recommendations\n# ============================\ndef hybrid_prediction(movie_row, user_id, svd, item_features, movie_id_map, ratings_matrix, \n                     ann_model, scaler_X, scaler_y, weight_svd=0.5, weight_ann=0.5):\n    \"\"\"\n    Creates a hybrid prediction combining SVD and ANN models.\n    \"\"\"\n    # Get SVD prediction\n    movie_id = movie_row['id']\n    svd_raw = predict_rating_svd(svd, item_features, user_id, movie_id, movie_id_map, ratings_matrix)\n    \n    # Get ANN prediction\n    features = movie_row[['budget', 'popularity', 'runtime']].values.reshape(1, -1)\n    ann_raw = predict_rating_ann(ann_model, scaler_X, scaler_y, features)\n    \n    # Combine predictions\n    combined = weight_svd * svd_raw + weight_ann * ann_raw\n    return combined","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:06:25.3039Z","iopub.execute_input":"2025-04-02T19:06:25.304428Z","iopub.status.idle":"2025-04-02T19:06:25.33003Z","shell.execute_reply.started":"2025-04-02T19:06:25.304378Z","shell.execute_reply":"2025-04-02T19:06:25.328723Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualization and Evaluation Functions","metadata":{}},{"cell_type":"code","source":"# ============================\n# Visualization and Evaluation Functions\n# ============================\ndef visualize_model_error(y_true, y_pred, model_name, color):\n    \"\"\"\n    Visualizes prediction errors for any model.\n    \"\"\"\n    mse = mean_squared_error(y_true, y_pred)\n    r2 = r2_score(y_true, y_pred)\n    \n    plt.figure(figsize=(8,6))\n    plt.scatter(y_true, y_pred, alpha=0.6, color=color)\n    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--')\n    plt.xlabel(\"True Ratings\")\n    plt.ylabel(f\"{model_name} Predicted Ratings\")\n    plt.title(f\"{model_name} Error Analysis: True vs Predicted\\nMSE={mse:.4f}, R²={r2:.4f}\")\n    plt.tight_layout()\n    plt.show()\n    \n    return mse, r2\n\ndef display_recommendation_table(movie_titles, similarity_scores, title_prefix=\"Recommended Movies\"):\n    \"\"\"\n    Displays recommendations in a formatted table.\n    \"\"\"\n    df = pd.DataFrame({\n        f'{title_prefix}': movie_titles,\n        'Similarity/Rating Score': similarity_scores\n    })\n    \n    styled_df = df.style.background_gradient(cmap='Blues', subset=['Similarity/Rating Score'])\\\n                     .set_properties(**{'text-align': 'center'})\\\n                     .set_table_styles([{'selector': 'th', 'props': [('text-align', 'center')]}])\n    \n    return styled_df\n\ndef display_hybrid_table(movies, svd_preds, ann_preds, hybrid_preds, sample_titles):\n    \"\"\"\n    Displays hybrid predictions in a formatted table.\n    \"\"\"\n    df = pd.DataFrame({\n        'Movie Title': sample_titles,\n        'Actual Rating': [movies[movies['title_tmdb'] == t].iloc[0]['vote_average'] for t in sample_titles],\n        'SVD Rating': svd_preds,\n        'ANN Rating': ann_preds,\n        'Hybrid Rating': hybrid_preds\n    })\n    \n    styled = df.style.background_gradient(cmap='Blues', subset=['SVD Rating'])\\\n                     .background_gradient(cmap='Greens', subset=['ANN Rating'])\\\n                     .background_gradient(cmap='Purples', subset=['Hybrid Rating'])\\\n                     .background_gradient(cmap='Reds', subset=['Actual Rating'])\\\n                     .set_properties(**{'text-align': 'center'})\\\n                     .set_table_styles([{'selector': 'th', 'props': [('text-align', 'center')]}])\n    \n    return styled","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:06:25.332879Z","iopub.execute_input":"2025-04-02T19:06:25.333344Z","iopub.status.idle":"2025-04-02T19:06:25.359036Z","shell.execute_reply.started":"2025-04-02T19:06:25.333275Z","shell.execute_reply":"2025-04-02T19:06:25.357796Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Main Execution","metadata":{}},{"cell_type":"code","source":"# ============================\n# Main Execution\n# ============================\ndef main():\n    print(\"=== Loading TMDB Data ===\")\n    tmdb_data = load_tmdb_data()\n    print(\"TMDB dataset shape:\", tmdb_data.shape)\n    \n    # Display dataset info\n    print(\"\\n=== Dataset Overview ===\")\n    print(tmdb_data.columns.tolist())\n    print(f\"Number of movies: {len(tmdb_data)}\")\n    print(f\"Average rating: {tmdb_data['vote_average'].mean():.2f}\")\n    \n    print(\"\\n=== Creating Synthetic User Ratings ===\")\n    ratings_matrix, ratings_long = create_synthetic_rating_matrix(tmdb_data, n_synthetic_users=100)\n    print(f\"Synthetic ratings shape: {ratings_matrix.shape}\")\n    print(f\"Synthetic ratings samples: {len(ratings_long)}\")\n    \n    # Create a mapping from movie_id to column index for SVD predictions\n    movie_id_map = {movie_id: i for i, movie_id in enumerate(ratings_matrix.columns)}\n    \n    print(\"\\n=== Content-Based (TFIDF) Recommendations ===\")\n    tfidf_matrix, tfidf = preprocess_content(tmdb_data)\n    query_movie = \"Interstellar\"  # Ensure this title exists in tmdb_data['title_tmdb']\n    \n    tfidf_titles, tfidf_scores = content_based_recommender(tmdb_data, tfidf_matrix, tfidf, query_movie, top_n=10)\n    styled_df_tfidf = display_recommendation_table(tfidf_titles, tfidf_scores, \"TFIDF Recommended Movies\")\n    display(styled_df_tfidf)\n    \n    print(\"\\n=== KNN-Based Recommendations ===\")\n    knn_titles, knn_distances, knn_ratings = knn_recommender(tfidf_matrix, tmdb_data, query_movie, n_neighbors=10)\n    \n    # Convert distances to similarity scores (1 - distance) for consistency\n    knn_similarities = 1 - knn_distances\n    styled_df_knn = display_recommendation_table(knn_titles, knn_similarities, \"KNN Recommended Movies\")\n    display(styled_df_knn)\n    \n    print(\"\\n=== Training SVD Model ===\")\n    svd, item_features, user_features = train_svd_model(ratings_matrix, n_components=50)\n    \n    print(\"\\n=== SVD-Based Recommendations ===\")\n    svd_titles, svd_scores = svd_recommender(tmdb_data, svd, item_features, movie_id_map, ratings_matrix, user_id=1, top_n=10)\n    styled_df_svd = display_recommendation_table(svd_titles, svd_scores, \"SVD Recommended Movies\")\n    display(styled_df_svd)\n    \n    print(\"\\n=== Model Evaluations ===\")\n\n    print(\"\\n=== TF-IDF Model Evaluation ===\")\n    tfidf_mse, tfidf_r2, y_true_tfidf, y_pred_tfidf = evaluate_tfidf(tmdb_data)\n    visualize_model_error(y_true_tfidf, y_pred_tfidf, \"TF-IDF\", \"orange\")\n    print(f\"TF-IDF Evaluation -> MSE: {tfidf_mse:.4f}, R²: {tfidf_r2:.4f}\")\n\n    \n    print(\"Evaluating KNN...\")\n    # Updated call: Pass only tmdb_data since evaluate_knn expects movies as first argument.\n    knn_mse, knn_r2, y_true_knn, y_pred_knn = evaluate_knn(tmdb_data)\n    visualize_model_error(y_true_knn, y_pred_knn, \"KNN\", \"green\")\n    \n    print(\"Evaluating SVD...\")\n    svd_mse, svd_r2, y_true_svd, y_pred_svd = evaluate_svd(svd, item_features, movie_id_map, ratings_matrix, ratings_long)\n    visualize_model_error(y_true_svd, y_pred_svd, \"SVD\", \"blue\")\n    \n    print(\"\\n=== ANN Model Training and Evaluation ===\")\n    ann_model, scaler_X, scaler_y, X_test, y_test = train_ann_model(tmdb_data)\n    \n    # Get original scale y_test and predictions\n    y_test_orig = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n    y_pred_ann = ann_model.predict(X_test, verbose=0)\n    y_pred_ann_orig = scaler_y.inverse_transform(y_pred_ann).flatten()\n    \n    ann_mse, ann_r2 = visualize_model_error(y_test_orig, y_pred_ann_orig, \"ANN\", \"purple\")\n    \n    print(\"\\n=== Hybrid Recommendations ===\")\n    \n    # Get a common set of recommended movies from all methods\n    common_titles = list(set(tfidf_titles) & set(knn_titles) & set(svd_titles))[:5]\n    if len(common_titles) < 5:\n        common_titles = list(tfidf_titles)[:5]  # Fallback to TFIDF recommendations\n    \n    # Get hybrid predictions for these titles\n    svd_preds = []\n    ann_preds = []\n    hybrid_preds = []\n    \n    for title in common_titles:\n        movie_row = tmdb_data[tmdb_data['title_tmdb'] == title].iloc[0]\n        movie_id = movie_row['id']\n        \n        # SVD prediction\n        svd_pred = predict_rating_svd(svd, item_features, 1, movie_id, movie_id_map, ratings_matrix)\n        svd_preds.append(svd_pred)\n        \n        # ANN prediction\n        features = movie_row[['budget', 'popularity', 'runtime']].values.reshape(1, -1)\n        ann_pred = predict_rating_ann(ann_model, scaler_X, scaler_y, features)\n        ann_preds.append(ann_pred)\n        \n        # Hybrid prediction\n        hybrid_pred = hybrid_prediction(movie_row, 1, svd, item_features, movie_id_map, ratings_matrix, \n                                      ann_model, scaler_X, scaler_y, 0.5, 0.5)\n        hybrid_preds.append(hybrid_pred)\n    \n    styled_hybrid = display_hybrid_table(tmdb_data, svd_preds, ann_preds, hybrid_preds, common_titles)\n    display(styled_hybrid)\n    \n    print(\"\\n=== Model Performance Comparison ===\")\n    models_df = pd.DataFrame({\n        'Model': ['KNN', 'SVD', 'ANN'],\n        'MSE': [knn_mse, svd_mse, ann_mse],\n        'R²': [knn_r2, svd_r2, ann_r2]\n    })\n    \n    styled_models_df = models_df.style.background_gradient(cmap='RdYlGn_r', subset=['MSE'])\\\n                                      .background_gradient(cmap='RdYlGn', subset=['R²'])\\\n                                      .set_properties(**{'text-align': 'center'})\\\n                                      .set_table_styles([{'selector': 'th', 'props': [('text-align', 'center')]}])\n    \n    display(styled_models_df)\n\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T19:06:33.116604Z","iopub.execute_input":"2025-04-02T19:06:33.116945Z","iopub.status.idle":"2025-04-02T19:10:46.025939Z","shell.execute_reply.started":"2025-04-02T19:06:33.11692Z","shell.execute_reply":"2025-04-02T19:10:46.024616Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}